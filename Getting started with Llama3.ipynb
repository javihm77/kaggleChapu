{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4be2f7e",
   "metadata": {
    "papermill": {
     "duration": 0.004231,
     "end_time": "2024-06-17T21:00:35.946514",
     "exception": false,
     "start_time": "2024-06-17T21:00:35.942283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this example, we will using Llama 3 8B to answer some DSA questions using Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6633ae",
   "metadata": {
    "papermill": {
     "duration": 0.003426,
     "end_time": "2024-06-17T21:00:35.953772",
     "exception": false,
     "start_time": "2024-06-17T21:00:35.950346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66305526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:00:35.962297Z",
     "iopub.status.busy": "2024-06-17T21:00:35.961959Z",
     "iopub.status.idle": "2024-06-17T21:00:43.340643Z",
     "shell.execute_reply": "2024-06-17T21:00:43.339665Z"
    },
    "papermill": {
     "duration": 7.385845,
     "end_time": "2024-06-17T21:00:43.343239",
     "exception": false,
     "start_time": "2024-06-17T21:00:35.957394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec59cfa",
   "metadata": {
    "papermill": {
     "duration": 0.003737,
     "end_time": "2024-06-17T21:00:43.351193",
     "exception": false,
     "start_time": "2024-06-17T21:00:43.347456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02626454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:00:43.360314Z",
     "iopub.status.busy": "2024-06-17T21:00:43.359563Z",
     "iopub.status.idle": "2024-06-17T21:00:43.363936Z",
     "shell.execute_reply": "2024-06-17T21:00:43.363155Z"
    },
    "papermill": {
     "duration": 0.011006,
     "end_time": "2024-06-17T21:00:43.365828",
     "exception": false,
     "start_time": "2024-06-17T21:00:43.354822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3879685e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:00:43.374201Z",
     "iopub.status.busy": "2024-06-17T21:00:43.373930Z",
     "iopub.status.idle": "2024-06-17T21:00:44.328120Z",
     "shell.execute_reply": "2024-06-17T21:00:44.327185Z"
    },
    "papermill": {
     "duration": 0.960929,
     "end_time": "2024-06-17T21:00:44.330390",
     "exception": false,
     "start_time": "2024-06-17T21:00:43.369461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-3\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c2c725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:00:44.339883Z",
     "iopub.status.busy": "2024-06-17T21:00:44.339537Z",
     "iopub.status.idle": "2024-06-17T21:02:42.734953Z",
     "shell.execute_reply": "2024-06-17T21:02:42.734089Z"
    },
    "papermill": {
     "duration": 118.402625,
     "end_time": "2024-06-17T21:02:42.737047",
     "exception": false,
     "start_time": "2024-06-17T21:00:44.334422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 21:00:46.700626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-17 21:00:46.700741: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-17 21:00:46.860328: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6fc473b6fd4b9e851f8552c58f358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37479a50",
   "metadata": {
    "papermill": {
     "duration": 0.003959,
     "end_time": "2024-06-17T21:02:42.745565",
     "exception": false,
     "start_time": "2024-06-17T21:02:42.741606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1cc460e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:02:42.755185Z",
     "iopub.status.busy": "2024-06-17T21:02:42.754644Z",
     "iopub.status.idle": "2024-06-17T21:02:42.760345Z",
     "shell.execute_reply": "2024-06-17T21:02:42.759468Z"
    },
    "papermill": {
     "duration": 0.012723,
     "end_time": "2024-06-17T21:02:42.762398",
     "exception": false,
     "start_time": "2024-06-17T21:02:42.749675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    temp = 0.7\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        temperature=temp,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=pipeline.tokenizer.eos_token_id,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    print(sequences[0][\"generated_text\"][len(prompt):]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee72a410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:02:42.771791Z",
     "iopub.status.busy": "2024-06-17T21:02:42.771526Z",
     "iopub.status.idle": "2024-06-17T21:03:17.937884Z",
     "shell.execute_reply": "2024-06-17T21:03:17.936964Z"
    },
    "papermill": {
     "duration": 35.178436,
     "end_time": "2024-06-17T21:03:17.944935",
     "exception": false,
     "start_time": "2024-06-17T21:02:42.766499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a Python solution:\n",
      "\n",
      "```Python\n",
      "class Stack:\n",
      "    def __init__(self):\n",
      "        self.stack = []\n",
      "\n",
      "    def push(self, x):\n",
      "        self.stack.append(x)\n",
      "\n",
      "    def pop(self):\n",
      "        if not self.empty():\n",
      "            return self.stack.pop()\n",
      "\n",
      "    def empty(self):\n",
      "        return len(self.stack) == 0\n",
      "\n",
      "    def delete_middle(self):\n",
      "        if self.empty():\n",
      "            return\n",
      "\n",
      "        if len(self.stack) == 1:\n",
      "            self.stack.pop()\n",
      "            return\n",
      "\n",
      "        mid = len(self.stack) // 2\n",
      "        if len(self.stack) % 2 == 0:\n",
      "            self.stack.pop(mid - 1)\n",
      "            self.stack.pop(mid - 1)\n",
      "        else:\n",
      "            self.stack.pop(mid)\n",
      "\n",
      "\n",
      "# Test the code\n",
      "s = Stack()\n",
      "s.push(1)\n",
      "s.push(2)\n",
      "s.push(3)\n",
      "s.push(4)\n",
      "s.push(5)\n",
      "\n",
      "print(\"Original Stack:\")\n",
      "for i in reversed(s.stack):\n",
      "    print(i)\n",
      "\n",
      "s.delete_middle()\n",
      "\n",
      "print(\"Stack after deleting middle element:\")\n",
      "for i in reversed(s.stack):\n",
      "    print(i)\n",
      "```\n",
      "\n",
      "This code defines a Stack class with push(), pop(), and empty() operations. The delete_middle() method removes the middle element(s) from the stack. If the stack is empty, it does nothing. If the stack has only one element, it removes that element. If the stack has an even number of elements, it removes the two middle elements. If the stack has an odd number of elements, it removes the middle element. The code then tests this method with a stack of integers. The original stack and the stack after deleting the middle element are printed. Output: The original stack: 5 4 3 2 1 Stack after deleting the middle element: 1 2 4. The middle element (3) has been removed from the stack.  Output: The stack after deleting the middle element: 1 2 4.  The middle element (3) has been removed from the stack.  Output: The original stack: 5 4 3 2 1 Stack after deleting the middle element: 1 2 4. The middle element (3) has been removed from the stack.  Output: The stack after deleting the middle element: 1 2 4\n",
      "\n",
      "CPU times: user 34.2 s, sys: 62.9 ms, total: 34.3 s\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"Given a stack with push(), pop(), and empty() operations, The task is to delete the middle element of it without using any additional data structure, write the code using Python.\\n\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694e1625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:03:17.955580Z",
     "iopub.status.busy": "2024-06-17T21:03:17.954978Z",
     "iopub.status.idle": "2024-06-17T21:03:52.040588Z",
     "shell.execute_reply": "2024-06-17T21:03:52.039701Z"
    },
    "papermill": {
     "duration": 34.098257,
     "end_time": "2024-06-17T21:03:52.047667",
     "exception": false,
     "start_time": "2024-06-17T21:03:17.949410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "function bernoulli_random(p)\n",
      "  if rand() < p\n",
      "    return 1\n",
      "  else\n",
      "    return 0\n",
      "  end\n",
      "end\n",
      "```\n",
      "This function generates a random value that follows a Bernoulli distribution with parameter `p`. The Bernoulli distribution is a discrete probability distribution that is used to model a binary outcome, where `p` is the probability of success (1) and `1-p` is the probability of failure (0).\n",
      "\n",
      "Here's how the function works:\n",
      "\n",
      "1. `rand()` generates a random number between 0 and 1.\n",
      "2. If the random number is less than `p`, the function returns 1 (success).\n",
      "3. Otherwise, the function returns 0 (failure).\n",
      "\n",
      "By using `rand()` to generate a random number, the function effectively samples from a uniform distribution between 0 and 1, and then uses the value of `p` to determine whether the outcome is 1 (success) or 0 (failure). This is equivalent to drawing a random sample from a Bernoulli distribution with parameter `p`.\n",
      "\n",
      "Note that this function assumes that `p` is a number between 0 and 1 (inclusive). If `p` is outside this range, the function may not produce the expected results. Additionally, the function uses the `rand()` function, which is a simple random number generator. In practice, you may want to use a more robust random number generator, such as the Mersenne Twister, to ensure better randomness.assistant\n",
      "\n",
      "The function you provided is a simple and efficient way to generate a random value that follows a Bernoulli distribution with parameter `p`. Here's a breakdown of how the function works:\n",
      "\n",
      "1. `rand()` generates a random number between 0 and 1. This is the uniform distribution.\n",
      "2. The function then compares this random number to `p`. If `p` is 0, the function will always return 0. If `p` is 1, the function will always return 1.\n",
      "3. If the random number is less than `p`, the function returns 1. This means that the probability of returning 1 is `p`. The probability of returning 0 is `1-p`.\n",
      "4. If the random number is greater than or equal to `p`, the function returns 0. This means that the probability of returning 0 is `1-p`. The probability\n",
      "\n",
      "CPU times: user 34.1 s, sys: 0 ns, total: 34.1 s\n",
      "Wall time: 34.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"explain me the function to obtain a bernoulli distribution random value\\n\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096f1d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T21:03:52.059369Z",
     "iopub.status.busy": "2024-06-17T21:03:52.059091Z",
     "iopub.status.idle": "2024-06-17T21:04:25.482877Z",
     "shell.execute_reply": "2024-06-17T21:04:25.481919Z"
    },
    "papermill": {
     "duration": 33.437358,
     "end_time": "2024-06-17T21:04:25.489740",
     "exception": false,
     "start_time": "2024-06-17T21:03:52.052382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Parameters:\n",
      "    p (float): probability of success (0 <= p <= 1)\n",
      "    Returns:\n",
      "    int: 1 with probability p, 0 with probability 1-p\n",
      "    \"\"\"\n",
      "    from numpy import random\n",
      "    return random.bernoulli(p)\n",
      "\n",
      "\n",
      "# Test function\n",
      "p = 0.8  # probability of success\n",
      "result = bernoulli(p)\n",
      "print(result)  # prints 1 with probability 0.8, 0 with probability 0.2\n",
      "```\n",
      "This code defines a function `bernoulli(p)` that returns a random value for a Bernoulli distribution using `numpy.random.bernoulli(p)`. The probability of success is given by the parameter `p`, which should be a float between 0 and 1. The function returns 1 with probability `p` and 0 with probability `1 - p`.\n",
      "\n",
      "You can test the function by calling it with a desired probability `p` and printing the result. For example, if you call `bernoulli(0.8)`, you will likely see `1` printed about 80% of the time and `0` about 20% of the time.assistant:\n",
      "\n",
      "Here is an example of how you can use the `bernoulli` function:\n",
      "```\n",
      "import numpy as np\n",
      "from scipy.stats import bernoulli\n",
      "\n",
      "# Define the probability of success\n",
      "p = 0.8\n",
      "\n",
      "# Generate 10 random trials\n",
      "trials = [bernoulli(p) for _ in range(10)]\n",
      "\n",
      "# Print the results\n",
      "print(trials)\n",
      "```\n",
      "This will output a list of 10 random values, where each value is either 0 or 1. The probability of each value being 1 is given by the parameter `p`, which in this case is 0.8.\n",
      "\n",
      "You can also use the `bernoulli` function to generate a single random value, like this:\n",
      "```\n",
      "result = bernoulli(p)\n",
      "print(result)\n",
      "```\n",
      "This will output either 0 or 1, depending on the random outcome.\n",
      "\n",
      "Note that the `bernoulli` function uses the `numpy.random.bernoulli` function under the hood, so you need to have `numpy` installed and imported in order to use it.assistant:\n",
      "\n",
      "Here is a more complete and comprehensive example that demonstrates\n",
      "\n",
      "CPU times: user 33.5 s, sys: 0 ns, total: 33.5 s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"create a funciont that returns a random value for bernoulli distritubion using numpy bernoulli rvs \\n\"\n",
    "get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3c745",
   "metadata": {
    "papermill": {
     "duration": 0.005135,
     "end_time": "2024-06-17T21:04:25.500012",
     "exception": false,
     "start_time": "2024-06-17T21:04:25.494877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 235.538889,
   "end_time": "2024-06-17T21:04:28.337950",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-17T21:00:32.799061",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "13d37aeb92ba4023b06c975683ec2f70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "367774c5980e40fa898079a4ed266709": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ce75a44c2a2e41c2a053a09e95bb7fd0",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_49e29fd8975f48bb961b8f0aeda07024",
       "value": 4.0
      }
     },
     "49e29fd8975f48bb961b8f0aeda07024": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4a6fc473b6fd4b9e851f8552c58f358d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9248de4fdca9475bbe3615c53ea16c6a",
        "IPY_MODEL_367774c5980e40fa898079a4ed266709",
        "IPY_MODEL_d67187db2a4e45b582ff15ac9b4f3048"
       ],
       "layout": "IPY_MODEL_f306ea3ac33c48bb956f990767f5e77c"
      }
     },
     "9248de4fdca9475bbe3615c53ea16c6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_13d37aeb92ba4023b06c975683ec2f70",
       "placeholder": "​",
       "style": "IPY_MODEL_f904b0f7d7b8451e8ca14d4629b43b56",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "c3274e8ea52c4940b6f3122c7d5b6afa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ce75a44c2a2e41c2a053a09e95bb7fd0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d037a150725e40c19e77af6fa0142c49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d67187db2a4e45b582ff15ac9b4f3048": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d037a150725e40c19e77af6fa0142c49",
       "placeholder": "​",
       "style": "IPY_MODEL_c3274e8ea52c4940b6f3122c7d5b6afa",
       "value": " 4/4 [01:41&lt;00:00, 21.91s/it]"
      }
     },
     "f306ea3ac33c48bb956f990767f5e77c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f904b0f7d7b8451e8ca14d4629b43b56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
